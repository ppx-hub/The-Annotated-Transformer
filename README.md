# The-Annotated-Transformer
for own study

源代码地址：https://github.com/harvardnlp/annotated-transformer

https://github.com/lucidrains/vit-pytorch

主要参考链接

- [为什么Transformer适合做多模态任务？](https://www.zhihu.com/question/441073210)

- [李宏毅2021/2022春机器学习课程](https://www.bilibili.com/video/BV1Wv411h7kN?p=39&vd_source=95f7bc70eb863231665c459cb14c813a)

- [万字逐行解析与实现Transformer，并进行德译英实战](https://blog.csdn.net/zhaohongfei_358/article/details/126085246)

- [层层剖析，让你彻底搞懂Self-Attention、MultiHead-Attention和Masked-Attention的机制和原理](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)

- [ViT论文逐段精读【论文精读】](https://www.bilibili.com/video/BV15P4y137jb/?spm_id_from=333.788&vd_source=95f7bc70eb863231665c459cb14c813a)

- [Self-Supervised Learning 超详细解读 (六)：MAE：通向 CV 大模型](https://zhuanlan.zhihu.com/p/432950958)

- [别再无聊地吹捧了，一起来动手实现 MAE(Masked Autoencoders Are Scalable Vision Learners) 玩玩吧！](https://zhuanlan.zhihu.com/p/439554945)

- [Masked Autoencoders(MAE)](https://zhuanlan.zhihu.com/p/444573241)

- [Multi30K dataset link is broken](https://github.com/pytorch/text/issues/1756)
